{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Web_Scraping_Code_Team_Rocket.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4Xoq8VTMNtPm","colab_type":"code","outputId":"d3fb7168-5b8a-43c7-ecdc-dd7e8495fa9b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## please note that this webscraper most likely won't work, \\\n","## thecarconnection.com has noticed the use of this webscraper and did not \\\n","## make use of different URLs for different trims anymore. i will attempt to \\\n","## update the code shortly, at a significant loss, because it will reduce \\\n","## the number of cars by a factor of 10-15. sorry for the inconvenience\n","\n","# import all the libraries useful for webscraping\n","\n","# work with beautiful soup\n","import bs4 as bs\n","from urllib.request import Request, urlopen\n","import pandas as pd\n","\n","# import on the decided website - carconnection (as of Nov)\n","website = \"https://www.thecarconnection.com\"\n","\n","# define a list of all new cars - obtained from the home page of the car connection\n","# use the fetch function and save the list\n","def new_cars():\n","    new_cars_list = []\n","    for a in fetch(website, \"/new-cars\").find_all(\"a\", {\"class\": \"add-zip\"}):\n","        new_cars_list.append(a['href'])\n","    return new_cars_list\n","\n","# define a list to save from the year_model overview\n","def year_model_():\n","    year_model_list = []\n","    for make in model_menu():\n","        for id in fetch(website, make).find_all(\"a\", {\"id\": \"ymm-nav-specs-btn\"}):\n","            year_model_().append(id['href'])\n","    year_model_list.remove(\"/specifications/buick_enclave_2019_fwd-4dr-preferred\")\n","    return year_model_list\n","\n","# trim function is from now on\n","def trims():\n","    trim_list = []\n","    for row in year_model_():\n","        div = fetch(website, row).find_all(\"div\", {\"class\": \"block-inner\"})[-1]\n","        div_a = div.find_all(\"a\")\n","        for i in range(len(div_a)):\n","            trim_list.append(div_a[-i]['href'])\n","    return trim_list\n","\n","# make the menu function for \n","def menu_fn1():\n","    menu_fn_list = []\n","    for make in new_cars():\n","        for div in fetch(website, make).find_all(\"div\", {\"class\": \"name\"}):\n","            menu_fn_list.append(div.find_all(\"a\")[0]['href'])\n","    return menu_fn_list\n","\n","# menu function 2\n","def menu_fn2():\n","    menu_fn2_list = []\n","    for make in menu_fn1():\n","        soup = fetch(website, make)\n","        for div in soup.find_all(\"a\", {\"class\": \"btn avail-now first-item\"}):\n","            menu_fn2_list.append(div['href'])\n","        for div in soup.find_all(\"a\", {\"class\": \"btn 1\"}): \n","            menu_fn2_list.append(div['href'])\n","    return menu_fn2_list\n","\n","# fetch the URL \n","def fetch(hostname, filename):\n","    return bs.BeautifulSoup(urlopen(Request(hostname + filename, headers={'User-Agent': 'X'})).read(), 'lxml')\n","\n","#pd.DataFrame(trims()).to_csv(<REDACTED>, index=False, header=None)\n","#trims = pd.read_csv(<REDACTED>)\n","\n","# the function for specifications\n","def specs():\n","    specs_table = pd.DataFrame()\n","    for row in trims.iloc[:, 0]:\n","        soup = fetch(website, row)\n","        specs_df = pd.DataFrame(columns=[soup.find_all(\"title\")[0].text[:-15]])\n","        msrp_text = soup.find_all(\"div\", {\"class\": \"price\"})[0]\n","        # length of the msrp will be found in this if loop\n","        if len(msrp_text.find_all(\"a\")) >= 1:\n","            specs_df.loc[\"MSRP\"] = msrp_text.find_all(\"a\")[0].text\n","        # find all - specifications\n","        for div in soup.find_all(\"div\", {\"class\": \"specs-set-item\"}):\n","            row_name = div.find_all(\"span\")[0].text\n","            row_value = div.find_all(\"span\")[1].text\n","            specs_df.loc[row_name] = row_value\n","        # add in the specifications tables\n","        specs_table = pd.concat([specs_table, specs_df], axis=1, sort=False)\n","    return specs_table\n","\n","#specs().to_csv(<REDACTED>)\n","specs"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function __main__.specs>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"JP9l9UuuTmlX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}